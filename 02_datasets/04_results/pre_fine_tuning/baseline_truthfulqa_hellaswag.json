{
  "model": "llama2_7b",
  "timestamp": "20251030_043418",
  "evaluation_stage": "baseline",
  "data_directory": "/content/drive/MyDrive/project/benchmark_data",
  "test_samples": {
    "gsm8k": 500,
    "mmlu": 500,
    "truthfulqa": 200,
    "hellaswag": 500
  },
  "random_seed": 42,
  "scores": {
    "truthfulqa": 0.385,
    "hellaswag": 0.734
  },
  "benchmark_descriptions": {
    "gsm8k": "Grade school math reasoning",
    "mmlu": "Multitask language understanding",
    "truthfulqa": "Truthfulness and informativeness",
    "hellaswag": "Commonsense reasoning"
  }
}